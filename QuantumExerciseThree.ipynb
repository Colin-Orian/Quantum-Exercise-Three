{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c366007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Make a dataset of points inside and outside of a circle\n",
    "def circle(samples, center=[0.0, 0.0], radius=np.sqrt(2 / np.pi)):\n",
    "    \"\"\"\n",
    "    Generates a dataset of points with 1/0 labels inside a given radius.\n",
    "\n",
    "    Args:\n",
    "        samples (int): number of samples to generate\n",
    "        center (tuple): center of the circle\n",
    "        radius (float: radius of the circle\n",
    "\n",
    "    Returns:\n",
    "        Xvals (array[tuple]): coordinates of points\n",
    "        yvals (array[int]): classification labels\n",
    "    \"\"\"\n",
    "    Xvals, yvals = [], []\n",
    "\n",
    "    for i in range(samples):\n",
    "        x = 2 * (np.random.rand(2)) - 1\n",
    "        y = 0\n",
    "        if np.linalg.norm(x - center) < radius:\n",
    "            y = 1\n",
    "        Xvals.append(x)\n",
    "        yvals.append(y)\n",
    "    return np.array(Xvals, requires_grad=False), np.array(yvals, requires_grad=False)\n",
    "\n",
    "\n",
    "def plot_data(x, y, fig=None, ax=None):\n",
    "    \"\"\"\n",
    "    Plot data with red/blue values for a binary classification.\n",
    "\n",
    "    Args:\n",
    "        x (array[tuple]): array of data points as tuples\n",
    "        y (array[int]): array of data points as tuples\n",
    "    \"\"\"\n",
    "    if fig == None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    reds = y == 0\n",
    "    blues = y == 1\n",
    "    ax.scatter(x[reds, 0], x[reds, 1], c=\"red\", s=20, edgecolor=\"k\")\n",
    "    ax.scatter(x[blues, 0], x[blues, 1], c=\"blue\", s=20, edgecolor=\"k\")\n",
    "    ax.set_xlabel(\"$x_1$\")\n",
    "    ax.set_ylabel(\"$x_2$\")\n",
    "\n",
    "\n",
    "Xdata, ydata = circle(500)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "plot_data(Xdata, ydata, fig=fig, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define output labels as quantum state vectors\n",
    "def density_matrix(state):\n",
    "    \"\"\"Calculates the density matrix representation of a state.\n",
    "\n",
    "    Args:\n",
    "        state (array[complex]): array representing a quantum state vector\n",
    "\n",
    "    Returns:\n",
    "        dm: (array[complex]): array representing the density matrix\n",
    "    \"\"\"\n",
    "    return state * np.conj(state).T\n",
    "\n",
    "\n",
    "label_0 = [[1], [0]]\n",
    "label_1 = [[0], [1]]\n",
    "state_labels = np.array([label_0, label_1], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46f8cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "# Install any pennylane-plugin to run on some particular backend\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qcircuit(params, x, y):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): single input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    for p in params:\n",
    "        qml.Rot(*x, wires=0)\n",
    "        qml.Rot(*p, wires=0)\n",
    "    return qml.expval(qml.Hermitian(y, wires=[0]))\n",
    "\n",
    "\n",
    "def cost(params, x, y, state_labels=None):\n",
    "    \"\"\"Cost function to be minimized.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        float: loss value to be minimized\n",
    "    \"\"\"\n",
    "    # Compute prediction for each input in data batch\n",
    "    loss = 0.0\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    \n",
    "    y = qml.math.toarray(y)\n",
    "    for i in range(len(x)):\n",
    "        f = qcircuit(params, x[i], dm_labels[y[i]])\n",
    "        loss = loss + (1 - f) ** 2\n",
    "    return loss / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c861dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(params, x, y, state_labels=None):\n",
    "    \"\"\"\n",
    "    Tests on a given set of data.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        predicted (array([int]): predicted labels for test data\n",
    "        output_states (array[float]): output quantum states from the circuit\n",
    "    \"\"\"\n",
    "    fidelity_values = []\n",
    "    dm_labels = [density_matrix(s) for s in state_labels]\n",
    "    predicted = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        fidel_function = lambda y: qcircuit(params, x[i], y)\n",
    "        fidelities = [fidel_function(dm) for dm in dm_labels]\n",
    "        best_fidel = np.argmax(fidelities)\n",
    "\n",
    "        predicted.append(best_fidel)\n",
    "        fidelity_values.append(fidelities)\n",
    "\n",
    "    return np.array(predicted), np.array(fidelity_values)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Accuracy score.\n",
    "\n",
    "    Args:\n",
    "        y_true (array[float]): 1-d array of targets\n",
    "        y_predicted (array[float]): 1-d array of predictions\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        score (float): the fraction of correctly classified samples\n",
    "    \"\"\"\n",
    "    score = y_true == y_pred\n",
    "    return score.sum() / len(y_true)\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "    \"\"\"\n",
    "    A generator for batches of the input data\n",
    "\n",
    "    Args:\n",
    "        inputs (array[float]): input data\n",
    "        targets (array[float]): targets\n",
    "\n",
    "    Returns:\n",
    "        inputs (array[float]): one batch of input data of length `batch_size`\n",
    "        targets (array[float]): one batch of targets of length `batch_size`\n",
    "    \"\"\"\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1479edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.397638 | Train accuracy: 0.475000 | Test Accuracy: 0.476000\n",
      "Epoch:  1 | Loss: 0.206243 | Train accuracy: 0.655000 | Test accuracy: 0.645000\n",
      "Epoch:  2 | Loss: 0.166793 | Train accuracy: 0.735000 | Test accuracy: 0.757500\n",
      "Epoch:  3 | Loss: 0.156578 | Train accuracy: 0.800000 | Test accuracy: 0.758000\n",
      "Epoch:  4 | Loss: 0.152372 | Train accuracy: 0.795000 | Test accuracy: 0.810000\n",
      "Epoch:  5 | Loss: 0.131218 | Train accuracy: 0.830000 | Test accuracy: 0.814500\n",
      "Epoch:  6 | Loss: 0.121748 | Train accuracy: 0.875000 | Test accuracy: 0.870500\n",
      "Epoch:  7 | Loss: 0.115726 | Train accuracy: 0.860000 | Test accuracy: 0.861000\n",
      "Epoch:  8 | Loss: 0.111747 | Train accuracy: 0.870000 | Test accuracy: 0.850000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-b8eb6b0cd177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mpredicted_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfidel_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0maccuracy_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mit\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-2c6fe6fa061e>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(params, x, y, state_labels)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mfidel_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mqcircuit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mfidelities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfidel_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdm_labels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mbest_fidel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfidelities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-2c6fe6fa061e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mfidel_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mqcircuit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mfidelities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfidel_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdm_labels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mbest_fidel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfidelities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-2c6fe6fa061e>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mfidel_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mqcircuit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mfidelities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfidel_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdm_labels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mbest_fidel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfidelities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         finite_diff = any(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\tape\\tape.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, device, params)\u001b[0m\n\u001b[0;32m   1322\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1324\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\tape\\tape.py\u001b[0m in \u001b[0;36mexecute_device\u001b[1;34m(self, params, device)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQubitDevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1355\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\_qubit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;31m# apply all circuit operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonalizing_gates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;31m# generate computational basis samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\tape\\tape.py\u001b[0m in \u001b[0;36mdiagonalizing_gates\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1006\u001b[0m                 \u001b[1;31m# some observables do not have diagonalizing gates,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m                 \u001b[1;31m# in which case we just don't append any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m                 \u001b[0mrotation_gates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonalizing_gates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\ops\\qubit\\observables.py\u001b[0m in \u001b[0;36mdiagonalizing_gates\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgates\u001b[0m \u001b[0mdiagonalizing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mHermitian\u001b[0m \u001b[0mobservable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \"\"\"\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mQubitUnitary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meigendecomposition\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eigvec\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\ops\\qubit\\matrix_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, wires, do_queue, *params)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;31m# here we issue a warning to check the operation, instead of raising an error outright.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             if not qml.math.allclose(\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             ):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(tensor1, tensor2)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\autoray\\autoray.py\u001b[0m in \u001b[0;36mdo\u001b[1;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfer_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_lib_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate training and test data\n",
    "num_training = 200\n",
    "num_test = 2000\n",
    "\n",
    "Xdata, y_train = circle(num_training)\n",
    "X_train = np.hstack((Xdata, np.zeros((Xdata.shape[0], 1), requires_grad=False)))\n",
    "\n",
    "Xtest, y_test = circle(num_test)\n",
    "X_test = np.hstack((Xtest, np.zeros((Xtest.shape[0], 1), requires_grad=False)))\n",
    "\n",
    "\n",
    "# Train using Adam optimizer and evaluate the classifier\n",
    "num_layers = 3\n",
    "learning_rate = 0.6\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "\n",
    "# initialize random weights\n",
    "params = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "#params = np.random.uniform(size=(num_layers, 3), requires_grad=False)\n",
    "\n",
    "predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "# save predictions with random weights for comparison\n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = cost(params, X_test, y_test, state_labels)\n",
    "\n",
    "print(\n",
    "    \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "        0, loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "for it in range(epochs):\n",
    "    for Xbatch, ybatch in iterate_minibatches(X_train, y_train, batch_size=batch_size):\n",
    "        params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, state_labels)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "    loss = cost(params, X_train, y_train, state_labels)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "            *res\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e39437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "def qiskitData():\n",
    "    adhoc_dimension = 2\n",
    "    train_features, train_labels, test_features, test_labels, adhoc_total = ad_hoc_data(\n",
    "        training_size = 20,\n",
    "        test_size = 5,\n",
    "        n = adhoc_dimension,\n",
    "        gap = 0.3,\n",
    "        plot_data = False, one_hot=False, include_sample_total=True\n",
    "    )\n",
    "\n",
    "    X_train = np.hstack((train_features, np.zeros((train_features.shape[0], 1), requires_grad=False)))\n",
    "    y_train = np.array(train_labels)\n",
    "\n",
    "    X_test = np.hstack((test_features, np.zeros((test_features.shape[0], 1), requires_grad=False)))\n",
    "    y_test = np.array(test_labels)\n",
    "    \n",
    "    return [[X_train, y_train], [X_test, y_test]]\n",
    "\n",
    "def pennyData():\n",
    "    # Generate training and test data\n",
    "    num_training = 200\n",
    "    num_test = 2000\n",
    "\n",
    "    Xdata, y_train = circle(num_training)\n",
    "    X_train = np.hstack((Xdata, np.zeros((Xdata.shape[0], 1), requires_grad=False)))\n",
    "\n",
    "    Xtest, y_test = circle(num_test)\n",
    "    X_test = np.hstack((Xtest, np.zeros((Xtest.shape[0], 1), requires_grad=False)))\n",
    "    \n",
    "    return [[X_train, y_train], [X_test, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe482a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qis = qiskitData()\n",
    "pen = pennyData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b5aed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qiskit\n",
      "[0 0 0 0 0 1 1 1 1 1]\n",
      "Penny\n",
      "[1 1 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Qiskit\")\n",
    "print(qis[1][1])\n",
    "print(\"Penny\")\n",
    "print(pen[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24812909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(data):\n",
    "    X_train = data[0][0]\n",
    "    y_train = data[0][1]\n",
    "    \n",
    "    X_test = data[1][0]\n",
    "    y_test = data[1][1]\n",
    "    # Train using Adam optimizer and evaluate the classifier\n",
    "    num_layers = 3\n",
    "    learning_rate = 0.6\n",
    "    epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "\n",
    "    # initialize random weights\n",
    "    params = np.random.uniform(size=(num_layers, 3), requires_grad=True)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    \n",
    "    \n",
    "    # save predictions with random weights for comparison\n",
    "    initial_predictions = predicted_test\n",
    "\n",
    "    loss = cost(params, X_test, y_test, state_labels)\n",
    "\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "            0, loss, accuracy_train, accuracy_test\n",
    "        )\n",
    "    )\n",
    "    for it in range(epochs):\n",
    "        for Xbatch, ybatch in iterate_minibatches(X_train, y_train, batch_size=batch_size):\n",
    "            params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, state_labels)\n",
    "\n",
    "        predicted_train, fidel_train = test(params, X_train, y_train, state_labels)\n",
    "        accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "        loss = cost(params, X_train, y_train, state_labels)\n",
    "\n",
    "        predicted_test, fidel_test = test(params, X_test, y_test, state_labels)\n",
    "        accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "        res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "        print(\n",
    "            \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "                *res\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fed17661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.335856 | Train accuracy: 0.505000 | Test Accuracy: 0.427000\n",
      "Epoch:  1 | Loss: 0.189876 | Train accuracy: 0.715000 | Test accuracy: 0.703000\n",
      "Epoch:  2 | Loss: 0.239731 | Train accuracy: 0.655000 | Test accuracy: 0.672500\n",
      "Epoch:  3 | Loss: 0.204974 | Train accuracy: 0.675000 | Test accuracy: 0.704500\n",
      "Epoch:  4 | Loss: 0.179007 | Train accuracy: 0.740000 | Test accuracy: 0.733500\n",
      "Epoch:  5 | Loss: 0.154216 | Train accuracy: 0.790000 | Test accuracy: 0.763500\n",
      "Epoch:  6 | Loss: 0.128915 | Train accuracy: 0.795000 | Test accuracy: 0.780500\n",
      "Epoch:  7 | Loss: 0.121703 | Train accuracy: 0.840000 | Test accuracy: 0.795000\n",
      "Epoch:  8 | Loss: 0.116218 | Train accuracy: 0.845000 | Test accuracy: 0.809000\n",
      "Epoch:  9 | Loss: 0.110943 | Train accuracy: 0.845000 | Test accuracy: 0.824500\n",
      "Epoch: 10 | Loss: 0.109037 | Train accuracy: 0.875000 | Test accuracy: 0.830000\n"
     ]
    }
   ],
   "source": [
    "prediction(pen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7aabc42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.441151 | Train accuracy: 0.475000 | Test Accuracy: 0.300000\n",
      "Epoch:  1 | Loss: 0.323448 | Train accuracy: 0.400000 | Test accuracy: 0.300000\n",
      "Epoch:  2 | Loss: 0.299307 | Train accuracy: 0.500000 | Test accuracy: 0.400000\n",
      "Epoch:  3 | Loss: 0.283851 | Train accuracy: 0.625000 | Test accuracy: 0.500000\n",
      "Epoch:  4 | Loss: 0.271292 | Train accuracy: 0.625000 | Test accuracy: 0.500000\n",
      "Epoch:  5 | Loss: 0.261641 | Train accuracy: 0.625000 | Test accuracy: 0.500000\n",
      "Epoch:  6 | Loss: 0.257978 | Train accuracy: 0.675000 | Test accuracy: 0.800000\n",
      "Epoch:  7 | Loss: 0.259715 | Train accuracy: 0.650000 | Test accuracy: 0.800000\n",
      "Epoch:  8 | Loss: 0.261314 | Train accuracy: 0.625000 | Test accuracy: 0.800000\n",
      "Epoch:  9 | Loss: 0.259427 | Train accuracy: 0.600000 | Test accuracy: 0.800000\n",
      "Epoch: 10 | Loss: 0.255455 | Train accuracy: 0.600000 | Test accuracy: 0.700000\n"
     ]
    }
   ],
   "source": [
    "prediction(qis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13b8dc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.70176968 1.57079633 0.        ]\n",
      " [4.52389342 2.76460154 0.        ]\n",
      " [3.64424748 4.58672527 0.        ]\n",
      " [3.01592895 5.34070751 0.        ]\n",
      " [3.51858377 0.43982297 0.        ]\n",
      " [0.87964594 6.22035345 0.        ]\n",
      " [4.77522083 2.32477856 0.        ]\n",
      " [5.84336234 4.52389342 0.        ]\n",
      " [0.75398224 5.34070751 0.        ]\n",
      " [5.40353936 4.90088454 0.        ]\n",
      " [3.14159265 0.87964594 0.        ]\n",
      " [3.51858377 4.77522083 0.        ]\n",
      " [4.83805269 2.26194671 0.        ]\n",
      " [5.15221195 2.19911486 0.        ]\n",
      " [4.46106157 2.136283   0.        ]\n",
      " [2.07345115 1.94778745 0.        ]\n",
      " [0.18849556 5.2150438  0.        ]\n",
      " [3.89557489 6.09468975 0.        ]\n",
      " [1.44513262 0.43982297 0.        ]\n",
      " [3.39292007 0.31415927 0.        ]\n",
      " [2.70176968 6.09468975 0.        ]\n",
      " [5.15221195 1.19380521 0.        ]\n",
      " [4.39822972 4.39822972 0.        ]\n",
      " [0.50265482 1.13097336 0.        ]\n",
      " [2.136283   3.01592895 0.        ]\n",
      " [2.57610598 4.64955713 0.        ]\n",
      " [1.31946891 1.00530965 0.        ]\n",
      " [4.39822972 0.31415927 0.        ]\n",
      " [5.34070751 1.44513262 0.        ]\n",
      " [3.76991118 0.81681409 0.        ]\n",
      " [5.59203492 3.95840674 0.        ]\n",
      " [0.50265482 1.31946891 0.        ]\n",
      " [2.45044227 5.71769863 0.        ]\n",
      " [3.83274304 0.06283185 0.        ]\n",
      " [2.136283   6.03185789 0.        ]\n",
      " [5.59203492 2.95309709 0.        ]\n",
      " [3.89557489 5.40353936 0.        ]\n",
      " [2.76460154 0.         0.        ]\n",
      " [6.22035345 0.50265482 0.        ]\n",
      " [3.58141563 1.50796447 0.        ]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(qis[0][0])\n",
    "print(qis[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b60a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.75739858e-01  9.51153269e-01  0.00000000e+00]\n",
      " [ 4.52931108e-01  8.30090252e-01  0.00000000e+00]\n",
      " [-3.92277072e-01  4.83733720e-01  0.00000000e+00]\n",
      " [ 4.28005417e-01 -4.10620029e-01  0.00000000e+00]\n",
      " [ 1.01632651e-01  2.54830223e-01  0.00000000e+00]\n",
      " [-3.77363783e-02  6.54357413e-01  0.00000000e+00]\n",
      " [ 6.65738084e-01  7.01201097e-01  0.00000000e+00]\n",
      " [ 6.06847138e-01 -2.38330456e-02  0.00000000e+00]\n",
      " [-2.37123404e-01  6.62752567e-01  0.00000000e+00]\n",
      " [-1.95970829e-02 -5.07257203e-01  0.00000000e+00]\n",
      " [ 1.46870646e-02 -7.16300356e-01  0.00000000e+00]\n",
      " [ 3.83258981e-01 -3.28157437e-01  0.00000000e+00]\n",
      " [-4.78682403e-01  9.13017492e-01  0.00000000e+00]\n",
      " [ 5.53761992e-01  5.74139005e-01  0.00000000e+00]\n",
      " [ 2.47443939e-01  6.78345621e-01  0.00000000e+00]\n",
      " [ 5.18324962e-01  1.97547408e-01  0.00000000e+00]\n",
      " [ 9.22248804e-01 -6.16810101e-01  0.00000000e+00]\n",
      " [ 8.86759438e-01 -1.97123676e-01  0.00000000e+00]\n",
      " [ 5.67979668e-02 -7.54521361e-01  0.00000000e+00]\n",
      " [ 8.02148778e-02  2.22413504e-01  0.00000000e+00]\n",
      " [ 9.95403084e-01  9.50384822e-01  0.00000000e+00]\n",
      " [ 9.32794584e-01 -3.03223880e-01  0.00000000e+00]\n",
      " [ 9.82532997e-01 -8.90436968e-02  0.00000000e+00]\n",
      " [ 7.03672518e-01 -5.67360062e-01  0.00000000e+00]\n",
      " [ 1.16663593e-02  9.32024192e-01  0.00000000e+00]\n",
      " [ 8.94062794e-01  3.67469756e-01  0.00000000e+00]\n",
      " [ 5.95628645e-01 -6.47146607e-01  0.00000000e+00]\n",
      " [ 4.43317099e-01  2.36101617e-01  0.00000000e+00]\n",
      " [-8.16896528e-01 -7.73681987e-01  0.00000000e+00]\n",
      " [-7.83112764e-01  4.48713870e-01  0.00000000e+00]\n",
      " [-7.16569584e-01 -6.45354578e-02  0.00000000e+00]\n",
      " [-2.86036388e-01  1.01008282e-01  0.00000000e+00]\n",
      " [ 4.12952974e-01  3.69445074e-01  0.00000000e+00]\n",
      " [ 3.10398318e-02 -7.13302528e-02  0.00000000e+00]\n",
      " [-2.04368810e-01  7.23819897e-01  0.00000000e+00]\n",
      " [-3.38296390e-01 -4.81268358e-01  0.00000000e+00]\n",
      " [ 4.86630987e-01 -2.80473077e-01  0.00000000e+00]\n",
      " [ 6.93997200e-01 -3.44222563e-01  0.00000000e+00]\n",
      " [ 4.03889649e-01 -9.09781987e-01  0.00000000e+00]\n",
      " [-2.28874240e-01 -3.13539650e-01  0.00000000e+00]\n",
      " [ 6.33357479e-01  9.34110806e-01  0.00000000e+00]\n",
      " [-7.82374466e-02  6.49672554e-01  0.00000000e+00]\n",
      " [ 3.99389402e-01  9.34771975e-01  0.00000000e+00]\n",
      " [ 6.22217029e-01 -8.45043868e-01  0.00000000e+00]\n",
      " [ 4.26563445e-01  7.09994308e-02  0.00000000e+00]\n",
      " [-9.67127884e-01 -4.97374083e-01  0.00000000e+00]\n",
      " [ 8.43510490e-01  8.52122746e-01  0.00000000e+00]\n",
      " [ 5.97700920e-01  9.63559207e-01  0.00000000e+00]\n",
      " [ 6.13090449e-01 -9.79591625e-01  0.00000000e+00]\n",
      " [-4.24331319e-01 -9.38751636e-01  0.00000000e+00]\n",
      " [-8.11784063e-01 -5.62318366e-01  0.00000000e+00]\n",
      " [ 7.11709265e-03  6.95064007e-01  0.00000000e+00]\n",
      " [ 7.23933512e-01  2.32403717e-01  0.00000000e+00]\n",
      " [ 8.56351878e-01  1.24653180e-04  0.00000000e+00]\n",
      " [ 7.78072088e-01 -9.18694873e-02  0.00000000e+00]\n",
      " [-4.45549985e-01  8.32825836e-01  0.00000000e+00]\n",
      " [-2.24129849e-01  6.80821769e-03  0.00000000e+00]\n",
      " [-3.42278735e-01  3.25675201e-01  0.00000000e+00]\n",
      " [ 9.90062450e-01 -9.48972902e-01  0.00000000e+00]\n",
      " [ 7.99696012e-01 -9.92147886e-01  0.00000000e+00]\n",
      " [-2.71544238e-01 -6.62786387e-01  0.00000000e+00]\n",
      " [ 5.14683561e-01 -8.98778318e-01  0.00000000e+00]\n",
      " [ 1.06969907e-01 -4.10147732e-01  0.00000000e+00]\n",
      " [-7.32659502e-01  5.43636424e-01  0.00000000e+00]\n",
      " [-5.65166331e-01 -5.52649576e-01  0.00000000e+00]\n",
      " [-4.49846430e-01  1.73533528e-01  0.00000000e+00]\n",
      " [ 3.19331863e-01 -9.64794953e-01  0.00000000e+00]\n",
      " [-5.16260728e-01 -1.38058315e-01  0.00000000e+00]\n",
      " [-3.36046096e-01  7.68341317e-01  0.00000000e+00]\n",
      " [ 5.75417462e-01  2.51780431e-01  0.00000000e+00]\n",
      " [-3.23915168e-01  4.01344690e-01  0.00000000e+00]\n",
      " [ 6.87276026e-01  1.89660755e-01  0.00000000e+00]\n",
      " [ 5.68922934e-01  4.98209923e-01  0.00000000e+00]\n",
      " [ 1.43474622e-01 -3.75633566e-01  0.00000000e+00]\n",
      " [ 4.91564316e-01 -5.86407267e-01  0.00000000e+00]\n",
      " [ 5.58976693e-01  6.09093384e-01  0.00000000e+00]\n",
      " [ 6.44289759e-01 -5.41680580e-02  0.00000000e+00]\n",
      " [-6.15038464e-01 -8.00552800e-01  0.00000000e+00]\n",
      " [ 4.86722501e-01  7.72522769e-01  0.00000000e+00]\n",
      " [ 3.01676718e-01 -7.11679879e-01  0.00000000e+00]\n",
      " [ 8.69792897e-01  9.78204029e-01  0.00000000e+00]\n",
      " [-1.33242780e-01  1.89650579e-01  0.00000000e+00]\n",
      " [ 5.54457040e-01  4.72779580e-01  0.00000000e+00]\n",
      " [ 9.35574384e-01 -7.70233818e-01  0.00000000e+00]\n",
      " [ 1.61449732e-01  3.83862839e-01  0.00000000e+00]\n",
      " [ 7.80196848e-01  7.48219255e-01  0.00000000e+00]\n",
      " [ 9.55999587e-01  2.41569079e-02  0.00000000e+00]\n",
      " [ 6.61521734e-01 -1.45436584e-01  0.00000000e+00]\n",
      " [-1.55372244e-01 -4.93303271e-01  0.00000000e+00]\n",
      " [ 6.36474574e-01  9.71630212e-01  0.00000000e+00]\n",
      " [-4.87316543e-01 -8.87736824e-01  0.00000000e+00]\n",
      " [ 6.31084875e-01  2.40460105e-01  0.00000000e+00]\n",
      " [ 9.19397601e-01 -4.95521562e-01  0.00000000e+00]\n",
      " [-8.57944684e-01 -1.51154783e-02  0.00000000e+00]\n",
      " [-8.29067954e-01 -4.76419998e-01  0.00000000e+00]\n",
      " [-7.48044278e-01 -5.51735641e-01  0.00000000e+00]\n",
      " [-7.87710694e-01  9.07811999e-01  0.00000000e+00]\n",
      " [-4.42874573e-01 -1.12204828e-01  0.00000000e+00]\n",
      " [ 7.97223615e-01  3.54643176e-01  0.00000000e+00]\n",
      " [ 2.36074961e-01  4.11126381e-01  0.00000000e+00]\n",
      " [ 6.57644514e-01  7.55338536e-01  0.00000000e+00]\n",
      " [ 2.85279341e-01  7.80014549e-01  0.00000000e+00]\n",
      " [ 7.07950549e-02 -4.45418287e-01  0.00000000e+00]\n",
      " [ 7.60153418e-01  8.29456548e-02  0.00000000e+00]\n",
      " [ 8.12275175e-01 -9.19664372e-01  0.00000000e+00]\n",
      " [-2.04968497e-01  8.95610037e-01  0.00000000e+00]\n",
      " [-5.00699814e-01  8.83072492e-01  0.00000000e+00]\n",
      " [ 9.07804922e-01  7.64284628e-01  0.00000000e+00]\n",
      " [ 1.27336090e-01  2.93878898e-01  0.00000000e+00]\n",
      " [ 7.39233997e-01  5.51794165e-01  0.00000000e+00]\n",
      " [ 2.60187699e-01  9.64518816e-01  0.00000000e+00]\n",
      " [ 3.71353273e-01  9.50963985e-01  0.00000000e+00]\n",
      " [-8.85223051e-01 -7.22079259e-01  0.00000000e+00]\n",
      " [-9.70823080e-02 -2.30241078e-01  0.00000000e+00]\n",
      " [ 5.65469683e-01 -6.78771947e-01  0.00000000e+00]\n",
      " [ 9.52190358e-01 -3.69868249e-01  0.00000000e+00]\n",
      " [-1.42152585e-01 -4.50509935e-01  0.00000000e+00]\n",
      " [ 1.58727235e-01 -8.82742599e-01  0.00000000e+00]\n",
      " [-7.00644989e-01  4.91595407e-01  0.00000000e+00]\n",
      " [-6.26998833e-01 -5.28971097e-01  0.00000000e+00]\n",
      " [ 5.85964471e-01 -8.13397643e-01  0.00000000e+00]\n",
      " [-1.25052354e-01 -9.53873226e-01  0.00000000e+00]\n",
      " [-3.06385201e-01  3.97962805e-01  0.00000000e+00]\n",
      " [-8.19793441e-01  7.76669254e-01  0.00000000e+00]\n",
      " [ 8.18998086e-01 -7.90019250e-01  0.00000000e+00]\n",
      " [ 9.81464873e-01 -4.04940893e-01  0.00000000e+00]\n",
      " [-8.31796658e-01 -9.89865771e-01  0.00000000e+00]\n",
      " [-1.82954208e-01  2.59619971e-01  0.00000000e+00]\n",
      " [-3.35641500e-01  6.73434731e-01  0.00000000e+00]\n",
      " [ 4.33212551e-01 -2.99676936e-01  0.00000000e+00]\n",
      " [ 4.68619333e-01  8.80975474e-01  0.00000000e+00]\n",
      " [-8.13808003e-01 -3.87792080e-01  0.00000000e+00]\n",
      " [-7.33481218e-02 -4.01974449e-03  0.00000000e+00]\n",
      " [ 8.43912898e-02 -3.98746187e-01  0.00000000e+00]\n",
      " [ 3.34519292e-01  2.90169007e-01  0.00000000e+00]\n",
      " [ 1.55643013e-01 -7.72476557e-01  0.00000000e+00]\n",
      " [-4.60642178e-02 -2.87546225e-01  0.00000000e+00]\n",
      " [-1.79230603e-02  8.43732871e-01  0.00000000e+00]\n",
      " [-3.89373137e-02 -9.72038416e-01  0.00000000e+00]\n",
      " [-1.22326524e-01  6.41296360e-01  0.00000000e+00]\n",
      " [ 5.60121846e-01  2.67801471e-02  0.00000000e+00]\n",
      " [-5.00461974e-01 -6.98226742e-02  0.00000000e+00]\n",
      " [ 1.27404439e-01  9.99742877e-01  0.00000000e+00]\n",
      " [ 2.88356180e-01  3.88529860e-01  0.00000000e+00]\n",
      " [-1.70917129e-02 -2.91020898e-01  0.00000000e+00]\n",
      " [ 6.25905967e-01 -1.01353513e-02  0.00000000e+00]\n",
      " [ 9.89380260e-01 -8.57588515e-02  0.00000000e+00]\n",
      " [-8.63999433e-01  3.65156274e-01  0.00000000e+00]\n",
      " [-9.06717098e-01 -4.98996806e-01  0.00000000e+00]\n",
      " [-2.92523494e-01  4.78967171e-01  0.00000000e+00]\n",
      " [-1.15281472e-02 -9.42708137e-01  0.00000000e+00]\n",
      " [ 2.33699703e-01 -1.77127525e-01  0.00000000e+00]\n",
      " [ 8.43669020e-01 -8.75377720e-04  0.00000000e+00]\n",
      " [ 4.17950292e-01 -5.62263015e-01  0.00000000e+00]\n",
      " [ 5.21947129e-01  4.41910621e-01  0.00000000e+00]\n",
      " [ 8.08163417e-01 -9.32356717e-01  0.00000000e+00]\n",
      " [-1.04998605e-01  3.58310805e-01  0.00000000e+00]\n",
      " [-8.09672200e-01 -1.78791866e-01  0.00000000e+00]\n",
      " [ 8.84293206e-01 -1.28131018e-01  0.00000000e+00]\n",
      " [ 9.70809567e-01 -8.86321878e-01  0.00000000e+00]\n",
      " [ 4.35659552e-01  1.62032472e-01  0.00000000e+00]\n",
      " [ 1.07935426e-03  9.41694803e-01  0.00000000e+00]\n",
      " [-7.40699199e-01  7.91997903e-01  0.00000000e+00]\n",
      " [ 3.82480822e-01 -4.82007853e-01  0.00000000e+00]\n",
      " [ 8.03338291e-01 -1.41410164e-01  0.00000000e+00]\n",
      " [ 6.28454656e-01 -2.22326966e-01  0.00000000e+00]\n",
      " [ 7.01861655e-01  2.73258237e-01  0.00000000e+00]\n",
      " [-7.17906733e-01  2.99326327e-01  0.00000000e+00]\n",
      " [-6.17310475e-01 -1.76154744e-01  0.00000000e+00]\n",
      " [-6.59408831e-01 -9.55967769e-01  0.00000000e+00]\n",
      " [-5.76226921e-01  7.27440474e-02  0.00000000e+00]\n",
      " [-3.68780644e-02  2.99419107e-03  0.00000000e+00]\n",
      " [-5.04626243e-01  3.70322401e-01  0.00000000e+00]\n",
      " [ 4.08526574e-01 -2.84064349e-01  0.00000000e+00]\n",
      " [ 7.62340177e-01  2.88046433e-01  0.00000000e+00]\n",
      " [ 4.26078551e-01 -4.45320164e-01  0.00000000e+00]\n",
      " [-9.98776730e-01  7.30751224e-01  0.00000000e+00]\n",
      " [ 6.44848769e-01 -7.53616224e-01  0.00000000e+00]\n",
      " [-2.51789730e-01  3.22678617e-01  0.00000000e+00]\n",
      " [ 3.04221714e-01  7.20700670e-01  0.00000000e+00]\n",
      " [-7.19463677e-01 -1.40120504e-01  0.00000000e+00]\n",
      " [-8.05551164e-01 -2.20809503e-01  0.00000000e+00]\n",
      " [-9.69785109e-01  7.96546130e-01  0.00000000e+00]\n",
      " [ 5.40879937e-02  6.99604522e-01  0.00000000e+00]\n",
      " [-8.80190598e-01 -5.45083779e-01  0.00000000e+00]\n",
      " [-4.81240010e-01 -2.26617011e-01  0.00000000e+00]\n",
      " [ 6.05732745e-01 -2.26884253e-01  0.00000000e+00]\n",
      " [-5.90692941e-01 -8.70019479e-01  0.00000000e+00]\n",
      " [-8.41016503e-01  5.20094412e-01  0.00000000e+00]\n",
      " [-1.10394018e-01  4.52362244e-01  0.00000000e+00]\n",
      " [ 3.64574244e-01 -7.29275076e-01  0.00000000e+00]\n",
      " [-7.14224132e-01  5.10684031e-01  0.00000000e+00]\n",
      " [ 4.42536587e-01 -2.43938466e-01  0.00000000e+00]\n",
      " [-8.45155473e-01 -9.75803957e-01  0.00000000e+00]\n",
      " [-4.23686101e-01 -9.81555453e-01  0.00000000e+00]\n",
      " [-5.39854758e-01 -1.60998520e-01  0.00000000e+00]\n",
      " [-7.57168469e-01 -7.91444484e-01  0.00000000e+00]\n",
      " [ 7.92874871e-01  1.70940058e-01  0.00000000e+00]\n",
      " [ 8.68911374e-01 -3.08347672e-01  0.00000000e+00]\n",
      " [ 3.54289875e-01 -5.90616651e-01  0.00000000e+00]]\n",
      "[0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1\n",
      " 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(pen[0][0])\n",
    "print(pen[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb92e678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pennylane.numpy.tensor.tensor'>\n",
      "<class 'pennylane.numpy.tensor.tensor'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae0a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
